# PyTorch-DeepLearning

* PyTorch를 자유자재로 사용하기 위한 목적으로 공부
* PyTorch 공부하면서 배운 것들 정리
* 참고 서적: [PyTorch로 시작하는 딥 러닝 입문(유원준 저/위키독스)](https://wikidocs.net/book/2788) 
*

---------------------------

## 목차
### 00. 파이토치 공식 문서 링크

### 01. 책 소개하기

### 02. 파이토치 기초(PyTorch Basic)
  #### 01. 파이토치 패키지의 기본 구성
#### 02. 텐서 조작하기(Tensor Manipulation) 1
#### 03. 텐서 조작하기(Tensor Manipulation) 2
#### 04. 파이썬 클래스(class)

### 03. 선형 회귀(Linear Regression)
#### 01. 선형 회귀(Linear Regression)
#### 02. 자동 미분(Autograd)
#### 03. 다중 선형 회귀(Multivariable Linear Regression)
#### 04. nn.Module로 구현하는 선형 회귀
#### 05. 클래스로 파이토치 모델 구현하기
#### 06. 미니 배치와 데이터 로드(Mini Batch and Data Load)
#### 07. 커스텀 데이터셋(Custom Dataset)

### 04. 로지스틱 회귀(Logistic Regression)
#### 01. 로지스틱 회귀(Logistic Regression)
#### 02. nn.Module로 구현하는 로지스틱 회귀
#### 03. 클래스로 파이토치 모델 구현하기

### 05. 소프트맥스 회귀(Softmax Regression)
#### 01. 원-핫 인코딩(One-Hot Encoding)
#### 02. 소프트맥스 회귀(Softmax Regression) 이해하기
#### 03. 소프트맥스 회귀의 비용 함수 구현하기
#### 04. 소프트맥스 회귀 구현하기
#### 05. 소프트맥스 회귀로 MNIST 데이터 분류하기

### 06. 인공 신경망(Artificial Neural Network)
#### 01. 머신 러닝 용어 이해하기
#### 02. 퍼셉트론(Perceptron)
#### 03. XOR 문제 - 단층 퍼셉트론 구현하기
#### 04. 역전파(BackPropagation)
#### 05. XOR 문제 - 다층 퍼셉트론 구현하기
#### 06. 비선형 활성화 함수(Activation Function)
#### 07. 다층 퍼셉트론으로 손글씨 분류하기
#### 08. 다층 퍼셉트론으로 MNIST 분류하기
#### 09. 과적합(Overfitting)을 막는 방법들
#### 10. 기울기 소실(Gradient Vanishing)과 폭주(Exploding)

### 07. 합성곱 신경망(Convolutional Neural Network)
#### 01. 합성곱과 풀링(Convolution and Pooling)
#### 02. CNN으로 MNIST 분류하기
#### 03. 깊은 CNN으로 MNIST 분류하기

### 08. 자연어 처리의 전처리
#### 01. 자연어 처리 전처리 이해하기
#### 02. 토치텍스트 튜토리얼(Torchtext tutorial) - 영어
#### 03. 토치텍스트 튜토리얼(Torchtext tutorial) - 한국어
#### 04. 토치텍스트(Torchtext)의 batch_first

### 09. 단어의 표현 방법
#### 01. NLP에서의 원-핫 인코딩(One-Hot Encoding)
#### 02. 워드 임베딩(Word Embedding)
#### 03. 워드투벡터(Word2Vec)
#### 04. 영어/한국어 Word2Vec 훈련시키기
#### 05. 임베딩 벡터의 시각화(Embedding Visualization)
#### 06. 글로브(Glove)
#### 07. 파이토치(PyTorch)의 nn.Embedding()
#### 08. 사전 훈련된 워드 임베딩(Pretrained Word Embedding)

### 10. 순환 신경망(Recurrent Neural Network)
#### 01. 순환 신경망(Recurrent Neural Network, RNN)
#### 02. 장단기 메모리(Long Short-Term Memory, LSTM)

### 11. 다대다 RNN을 이용한 텍스트 생성
#### 01. 문자 단위 RNN(Char RNN)
#### 02. 문자 단위 RNN(Char RNN) - 더 많은 데이터
#### 03. 단어 단위 RNN - 임베딩 사용

### 12. 다대일 RNN을 이용한 텍스트 분류
#### 01. 파이토치를 이용한 텍스트 분류(Text classification using PyTorch)
#### 02. IMDB 리뷰 감성 분류하기(IMDB Movie Review Sentiment Analysis)

### 13. 시퀀스 레이블링(Sequence Labeling)
#### 01. 시퀀스 레이블링(Sequence Labeling)
#### 02. 양방향 RNN을 이용한 품사 태깅

### 14. 시퀀스투시퀀스(Sequence-to-Sequence, seq2seq)
#### 01. 시퀀스투시퀀스(Sequence-to-Sequence, seq2seq)
#### 02. seq2seq 구현하기 (간단 버전)

---------------------------

## 공부하면서 느낀점
20210320 - 하나를 알기 위해 두 개를 더 공부해야 할 거 같다. 모르는 것들 투성이다. 내 방식대로, 제 3자가 봐도 이해할 수 있게 공부한 내용을 정리해야 할 거 같다.
